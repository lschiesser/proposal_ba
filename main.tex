\documentclass[12pt,a4paper,oneside]{article}
\usepackage[a4paper,width=150mm,top=25mm,bottom=25mm,bindingoffset=6mm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\graphicspath{ {images/} }
\usepackage[style=numeric]{biblatex}
\addbibresource{refs.bib}
\pagenumbering{gobble}
\newcommand{\code}{\texttt}
\newcommand{\comment}[1]{}
\usepackage{hyperref}

\title{Proposal}
\author{Lukas Schie√üer}
\date{}

\begin{document}
\maketitle
In December 2019, a novel coronavirus named Sars-CoV-2 emerged in China, spreading around the world rapidly, leading the World Health Organization to declare a global pandemic. Due to its diverse symptomatology, the disease caused by this virus cannot be diagnosed by overt symptoms alone. A PCR test indicating the presence of the virus is needed to confirm its contraction.
The pandemic overwhelmed healthcare systems across the globe, leading to worldwide shortages in testing reagents and equipment, which continue to arise now and will occur again in the future. \cite{jaecklin_2020, asm.org_2020}
As a consequence of testing supply shortages, hospitals face the difficult decision of whom to test for this disease.
Artificial Intelligence techniques can help to manage testing capacities by identifying patients with this disease or by predicting the probability of a positive test using, e.g., standard blood screening. These techniques, combined with additional data and observations, might allow physicians and health care workers to make better decisions about the administration of tests.
\par
The goal of my bachelor's thesis is to reproduce some of the classifiers implemented in \citeauthor{RN127}, \citeyear{RN127} \cite{RN127}. \citeauthor{RN127} use different classifiers to predict the outcome of a PCR test for Sars-CoV-2 based on a routine blood screening. The \href{https://zenodo.org/record/3886927/files/covid_study_v2.xlsx?download=1}{data} used to train these classifiers is provided by the authors of the paper. It was collected between the end of February 2020 and mid of March 2020 from patients admitted to the \textit{IRCSS Ospedale San Raffaele}\footnote{University hospital in Milan, Italy} and consists of 279 individuals who where selected randomly. For each individual, the data set provides their age, gender, results of a routine blood screening, and the result of a PCR test for Sars-CoV-2. The data set is only slightly imbalanced towards positive cases with 177 (63\%) positive and 102 (37\%) negative cases.
\par
To impute missing values in the data, the researchers use a method called \textit{multivariate imputation by chained equations} (short: MICE). MICE is a method that imputes missing data by estimating a set of possible values from distributions of observed data. Each variable with missing data $x_n$ is regressed on all other variables $x_1, ..., x_k$, which are restricted to the occurrences with observed data in $x_n$. Thereby, this procedure can reflect the statistical uncertainty during the imputation process. Moreover, by modeling every variable individually, MICE can handle variables of different types. Usually, the data set is imputed several times to produce slightly different imputed data sets which also reflect the uncertainty in the imputations. These imputed data sets are then used during the analysis or training phase. Their estimates are then pooled together to achieve a final result. \cite{RN141,RN142, RN144} The authors use 5-fold nested cross-validation to tune the hyperparameters of the classifiers and train them. During this process, the data is also imputed.
\par
\citeauthor{RN127} implement seven different classifiers, including logistic regression and random forests which I plan to implement. All classifiers are evaluated using accuracy, balanced accuracy, positive predictive value, sensitivity, and area under the ROC-curve. I will adopt these evaluation metrics since they are important measures for every medical test and model.
In Python, the MICE algorithm is implemented by the class \code{IterativeImputer} in scikit-learn \cite{scikit-learn}. Unfortunately, this implementation is still experimental and poses some shortcomings. Most prominently, this implementation is not yet able to handle non-normally distributed variables. Additionally, the Python implementation does not provide detailed information about the individual models used to impute the missing values, as other implementations of this algorithm in other languages and frameworks do. Therefore, I decided to use the R implementation of the algorithm called \code{mice()} \cite{RN135}. It can handle non-normal variables and provides functions to examine the parameters of the individual distributions in great detail which can be helpful to determine the suitability of the model for each variable \cite{RN142}. Since the majority of the data analysis and model fitting is executed in Python there are two possibilities to impute the missing data using MICE in R. On the one hand, the data could be preprocessed in R and then exported to be subsequently used in the Python implementation of the 5-fold nested cross-validation. 
On the other hand, I could use the R API to incorporate the R code in Python and impute the missing values during the 5-fold nested cross validation as proposed by the authors. I will try to implement the latter possibility since this is proposed by the authors and can help investigate the influence of the imputation procedure on the results of the classifiers.
The acquired evaluation metrics for each classifier should then be compared to those in the original paper and could also be compared to studies concerned with changes in blood values resulting from a coronavirus infection. Further, I am going to train a decision tree to gain some insight into the importance of the features in the data set. Finally, in the discussion, I would like to consider the advantages and shortcomings of the MICE algorithm, the analysis, and the training process. Additionally, I would like to discuss scenarios for real-world validation of the results of the classifiers.
% think about if you really want to talk about bootstrapping
\comment{
Additionally, I could discuss further ideas, such as the potential benefits and pitfalls of bootstrapping data using the original data set to improve the performance of the classifiers and scenarios for a real-world validation of the results.}
\printbibliography
\end{document}
